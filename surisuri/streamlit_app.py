import streamlit as st
from gpt_handler import analyze_long_text
from rule_engine import analyze_with_rules
from visualizer import show_visualizations
import json
import pandas as pd
import os

st.set_page_config(page_title="Codex ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ’¬ Codex (GPT) ê¸°ë°˜ ë¶„ì„ê¸°")

# ì…ë ¥ ëª¨ë“œ ì„ íƒ
input_mode = st.radio("ì…ë ¥ ë°©ë²• ì„ íƒ", ["ì§ì ‘ ì…ë ¥", "íŒŒì¼ ì—…ë¡œë“œ"])
user_input = ""

# ì…ë ¥ ì²˜ë¦¬
if input_mode == "ì§ì ‘ ì…ë ¥":
    user_input = st.text_area("ğŸ” ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", height=300)
elif input_mode == "íŒŒì¼ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader("ğŸ“‚ JSON íŒŒì¼ ì—…ë¡œë“œ (input_saju_data.json)", type="json")
    if uploaded_file:
        try:
            user_input = json.load(uploaded_file)
            user_input = json.dumps(user_input, ensure_ascii=False, indent=2)
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

# ë¶„ì„ ë²„íŠ¼: GPT
if st.button("ğŸš€ GPT ë¶„ì„ ì‹¤í–‰") and user_input:
    st.markdown("## âœ… GPT ë¶„ì„ ê²°ê³¼")
    result = analyze_long_text(user_input)
    st.text_area("ğŸ“˜ GPT ìš”ì•½ ê²°ê³¼", result, height=300)

    st.download_button("ğŸ“¥ ê²°ê³¼ ì €ì¥ (.md)", data=result, file_name="gpt_results.md")

# ë¶„ì„ ë²„íŠ¼: ê·œì¹™ ê¸°ë°˜
if st.button("âš™ï¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„") and user_input:
    st.markdown("## ğŸ§  ê·œì¹™ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼")
    result = analyze_with_rules(user_input)
    st.json(result)

    # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸
    os.makedirs("export", exist_ok=True)

    # ê²°ê³¼ ì €ì¥
    df = pd.DataFrame([result])
    df.to_csv("export/results.csv", index=False)
    df.to_excel("export/results.xlsx", index=False)
    st.success("CSV / XLSX ì €ì¥ ì™„ë£Œ!")

# ì‹œê°í™” ë²„íŠ¼
if st.button("ğŸ“Š ì‹œê°í™” ë³´ê¸°") and user_input:
    st.markdown("## ğŸ“ˆ ë¶„ì„ ì‹œê°í™”")
    show_visualizations()
